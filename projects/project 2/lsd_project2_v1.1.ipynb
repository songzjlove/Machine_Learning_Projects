{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# LSD Projecct 2\n",
      "# Zhengjian Song\n",
      "# Part 1\n",
      "\n",
      "import DAL\n",
      "import time\n",
      "import string\n",
      "import re\n",
      "import fractions\n",
      "import numpy\n",
      "import scipy\n",
      "import time\n",
      "from numpy import arange,array,ones,linalg\n",
      "from pylab import plot,show\n",
      "from __future__ import division\n",
      "from IPython.parallel import Client\n",
      "import matplotlib.pyplot as plt \n",
      "\n",
      "rc = Client()\n",
      "dview = rc[:]\n",
      "wishes=DAL.create('wishes')\n",
      "data = wishes.subsets()[13:18] #use only one recent week of twitter data to get the volcabulary,  \n",
      "\n",
      "# Clean the raw text data with filters\n",
      "# Create a very long string comprising of the first 5 days of twitter data\n",
      "dictionary= {}\n",
      "for i in range(len(data)):\n",
      "    print 'day', i\n",
      "    text = \"\"\n",
      "    for tweet in wishes.iter(data[i]):\n",
      "        if tweet.has_key('text'):\n",
      "            lower = tweet['text'].lower()\n",
      "            text += lower\n",
      "        else:\n",
      "            #print i\n",
      "            break\n",
      "    text = re.sub(r'@[a-zA-Z0-9_]+', \"\", text) #removes the @bullshit\n",
      "    text = re.sub(r'[^\\x00-\\x7F]', \"\", text) #removes weird shit\n",
      "    text = re.sub(r'&[a-zA-Z0-9_]+', \"\", text)#removes &amp etc.\n",
      "    text = re.sub(r'\\W', \" \", text) #removes anything which is not alphanumeric\n",
      "    text = re.sub(r'[0-9]', \"\", text) #removes #s\n",
      "    text = re.sub(r\"\\s+\", \" \", text) #removing white space\n",
      "    #print text\n",
      "    #splitting text into words\n",
      "    tt = text.split()\n",
      "    for word in tt:\n",
      "        if len(word) >= 2:\n",
      "            if dictionary.has_key(word):\n",
      "                dictionary[word] = dictionary[word] + 1\n",
      "            else:\n",
      "                dictionary.setdefault(word, 1)\n",
      "    \n",
      "#print len(dictionary.keys()) #\n",
      "#Trim the dictionary, each word has at least 25 occurances.\n",
      "V = []\n",
      "for word in dictionary.keys():\n",
      "    if dictionary[word] > 25:\n",
      "        V.append(word)\n",
      "M = len(V)\n",
      "print 'get the V(representation) and its size equals ', len(V)\n",
      "print V"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "day 0\n",
        "day"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "day"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "day"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "day"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "day"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "get the V(representation) and its size equals "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 566\n",
        "[u'here', u'music', u'until', u'successful', u'brings', u'want', u'organizer', u'travel', u'how', u'hot', u'__', u'allah', u'message', u'rt', u're', u'tahun', u'person', u'came', u'saying', u'lessons', u'best', u'lots', u'pre', u'much', u'life', u'udah', u'things', u'had', u'macdonald', u'right', u'people', u'for', u'condit', u'support', u'happy', u'roll', u'time', u'leave', u'team', u'sign', u'love', u'tidak', u'lalalala', u'awesome', u'ss', u'st', u'so', u'sa', u'years', u'records', u'one', u'open', u'boyfriend', u'san', u'sad', u'say', u'take', u'lotus', u'going', u'xmas', u'many', u'singapore', u'renewable', u'summer', u'being', u'rest', u'joyful', u'around', u'dari', u'world', u'favorite', u'other', u'her', u'hey', u'with', u'gone', u'am', u'an', u'as', u'at', u'graduate', u'th', u'full', u'via', u'militarysniperpinfall', u'more', u'beautiful', u'its', u'always', u'really', u'try', u'guest', u'show', u'also', u'play', u'plan', u'exo', u'ugh', u'factor', u'loved', u'set', u'jadi', u'see', u'whole', u'hoping', u'semoga', u'parents', u'couple', u'be', u'santa', u'by', u'into', u'up', u'us', u'ur', u'un', u'hello', u'send', u'anxious', u'video', u'let', u'great', u'thats', u'next', u'this', u'clients', u'high', u'sleepwalk', u'perfect', u'doing', u'put', u'lol', u'tonight', u'justinmeetbeliebitshawty', u'jungsoo', u'bring', u'should', u'jan', u'hope', u'meant', u've', u'off', u'indonesia', u'kiss', u'less', u'become', u'semua', u'official', u'chance', u'tickets', u'follow', u'told', u'festive', u'aku', u'bro', u'haha', u'work', u'could', u'after', u'then', u'them', u'break', u'they', u'another', u'do', u'di', u'de', u'da', u'buat', u'away', u'we', u'families', u'has', u'the', u'thanks', u'jose', u'night', u'marketing', u'way', u'was', u'true', u'welcome', u'together', u'gue', u'change', u'market', u'super', u'live', u'car', u'can', u'december', u'spm', u'write', u'goal', u'still', u'not', u'now', u'en', u'year', u'happen', u'album', u'looking', u'card', u'care', u'xx', u'tomorrow', u'friend', u'that', u'than', u'forever', u'only', u'truly', u'concert', u'notice', u'pray', u'comes', u'hve', u'sehat', u'these', u'biar', u'followers', u'greetings', u'co', u'real', u'gonna', u'early', u'business', u'your', u'start', u'lot', u'sales', u'you', u'since', u'very', u'louis', u'instagram', u'hahaha', u'soldier', u'family', u'hurry', u'dream', u'help', u'soon', u'actually', u'yg', u'yr', u'bless', u'event', u'pun', u'miss', u'wonderful', u'kai', u'close', u'won', u'damn', u'teuk', u'ada', u'look', u'mahasiswa', u'ready', u'remaining', u'march', u'some', u'seeing', u'visit', u'within', u'nak', u'gw', u'ga', u'go', u'win', u'justin', u'meet', u'his', u'heres', u'special', u'kalian', u'management', u'need', u'makeover', u'kong', u'she', u'merry', u'both', u'party', u'http', u'keep', u'well', u'twitter', u'home', u'artiste', u'ht', u'hi', u'he', u'stay', u'friends', u'sorry', u'even', u'new', u'ever', u'never', u'met', u'fantastic', u'tell', u'give', u'amazing', u'before', u'personal', u'better', u'weeks', u'untuk', u'luck', u'don', u'ending', u'stop', u'bad', u'brazil', u'said', u'omg', u'were', u'lovely', u'prosperous', u'lebih', u'is', u'it', u'cant', u'im', u'in', u'if', u'make', u'yours', u'just', u'yes', u'yet', u'dreams', u'dear', u'down', u'shit', u'finally', u'me', u'did', u'wait', u'everybody', u'making', u'fuck', u'till', u'nya', u'mau', u'may', u'guys', u'man', u'maybe', u'thank', u'girl', u'advance', u'thing', u'think', u'first', u'long', u'sounds', u'little', u'gladimet', u'get', u'calendar', u'tour', u'folow', u'wake', u'those', u'sama', u'same', u'money', u'blessed', u'again', u'students', u'starting', u'two', u'justinmeetjamaica', u'taun', u'dec', u'coming', u'already', u'through', u'thnx', u'good', u'everyone', u'energy', u'dont', u'punya', u'done', u'mama', u'para', u'park', u'part', u'believe', u'most', u'ke', u'ko', u'find', u'please', u'fans', u'point', u'fun', u'safe', u'spend', u'snap', u'excited', u'big', u'back', u'ufc', u'from', u'bisa', u'forward', u'got', u'flat', u'la', u'll', u'dan', u'day', u'february', u'greysonchancefeatjustinbieber', u'have', u'kita', u'overfl', u'staff', u'suatu', u'lulus', u'nd', u'almost', u'kkkk', u'like', u'success', u'about', u'biggest', u'but', u'antiknock', u'wish', u'pic', u'resolution', u'sleep', u'tweet', u'every', u'school', u'enjoy', u'would', u'to', u'my', u'end', u'amin', u'over', u'god', u'free', u'wanted', u'days', u'top', u'too', u'ray', u'though', u'yang', u'baik', u'watch', u'hopefully', u'news', u'been', u'gift', u'malaysia', u'everything', u'christmas', u'class', u'lagi', u'hear', u'practicing', u'trip', u'ni', u'no', u'na', u'when', u'ng', u'yall', u'goes', u'kamu', u'healthy', u'iphone', u'msg', u'today', u'birthday', u'yuk', u'season', u'and', u'ang', u'any', u'sure', u'rematch', u'jakarta', u'come', u'pop', u'direction', u'myself', u'someone', u'check', u'ya', u'lets', u'on', u'ok', u'oh', u'of', u'or', u'mas', u'there', u'all', u'program', u'worst', u'list', u'what', u'bulls', u'glad', u'nanti', u'style', u'sukses', u'health', u'nothing', u'pengen', u'him', u'baru', u'are', u'pm', u'advise', u'holidays', u'customers', u'wanna', u'because', u'xoxo', u'fast', u'peace', u'nice', u'wishes', u'apa', u'use', u'something', u'instead', u'holiday', u'our', u'out', u'their', u'aamiin', u'who', u'closed', u'joy', u'job', u'april', u'makin', u'respect', u'last', u'present', u'will', u'erie', u'gets', u'happiness', u'know', u'january', u'getting', u'made', u'ex', u'walafiat', u'book', u'june', u'kurang']\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The feature representation we chose is a vocabulary of words. We used the tweets from the week before the testing data (i.e. Dec 20th onwards). We used the wishes data to create the dictionary since in the original printout of the instructions, we were told to look at the wishes data. We also chose to use just the tweets from only the week before the testing data since we did not feel that using the entire set of training data would be useful. Thus we will be looking at each of the tweets from Dec 20 onwards and then cleaning it up and checking of the invidual words which comprise the tweets can be found in the vocabulary. If so, we update the feature vector by 1 in that spot taken by the word and 0 if not. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# LSD Projecct 2\n",
      "# Michelle Yeo and Zhengjian Song\n",
      "# Part 2\n",
      "\n",
      "# L2-regularization online update beta function. \n",
      "def online_update_beta_l2(y_label, mu, xvec, beta, b0, eta, rambda):\n",
      "    new_b0 = 0\n",
      "    new_beta = np.zeros(len(beta))\n",
      "    pp = 1/(1+exp(-1* mu))\n",
      "    new_b0 = b0 + eta*((y_label - pp) - rambda)\n",
      "    new_beta = beta + eta * ((y_label - pp )* xvec - rambda)\n",
      "    return (new_b0,new_beta)\n",
      "\n",
      "# Different learning rates\n",
      "def learning( ty, t):\n",
      "    # Switch\n",
      "    if ty == 0:\n",
      "        return 0.1\n",
      "    elif ty == 1:\n",
      "        return 0.5\n",
      "    elif ty == 2:\n",
      "        return 1.0\n",
      "    #\n",
      "    elif ty == 3:\n",
      "        return 0.3/t\n",
      "    elif ty == 4:\n",
      "        return 1/t\n",
      "    elif ty == 5:\n",
      "        return 2/t\n",
      "    #\n",
      "    elif ty == 6:\n",
      "        return 0.3/sqrt(t)\n",
      "    elif ty == 7:\n",
      "        return 1/sqrt(t)\n",
      "    elif ty == 8:\n",
      "        return 5/sqrt(t)\n",
      "    \n",
      "    else:\n",
      "        return 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NOTE: The training is fast enough, but loading the data will take a while.\n",
      "One possible way is to load all data at first, and then train models online with different learning rate, but this will lead to the kernel crash (out of memory) problem.\n",
      "Or one could train the model with different learning rate with loading the data only once, but the code will be ugly with 9 sets of error counts variable. Besides, you will see the results together in the end not one by one, which means, it will really take you a while to see the result to check the codes.\n",
      "\n",
      "Wanna be faster? please try the code:\n",
      "test = lwishes.subsets()[20:24]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this function trains one set of online data using stochastic gradient descent, it updates the parameters that we have gotten already\n",
      "def online_ridge_logistic(learning_type, g_beta, g_b0, g_t, f):\n",
      "    #parameters, L, l, M --- tweets of one new day.\n",
      "    #parameters, V --- vocabulary\n",
      "    #parameters, f --- file to write predicted label for unlabeled tweets\n",
      "    #parameters, errors stuff --- stat the errors\n",
      "    #parameters, g_beta, g_b0 --- global parameter\n",
      "    \n",
      "    # the rambda here usually should be from CV, for online training?\n",
      "    rambda = 0.001 #lambda penalty for ridge logistic regression\n",
      "    \n",
      "    errors = 0\n",
      "    #using SGD to update betas\n",
      "    for k in xrange(L):\n",
      "    #for k in range(20):\n",
      "        #normalising tweet i.e cleaning it up\n",
      "        temp = l[k]['text']\n",
      "        temp = re.sub(r'@[a-zA-Z0-9_]+', \"\", temp)\n",
      "        temp = re.sub(r'[^\\x00-\\x7F]', \"\", temp)\n",
      "        temp = re.sub(r'&[a-zA-Z0-9_]+', \"\", temp)\n",
      "        temp = re.sub(r'\\W', \" \", temp)\n",
      "        temp = re.sub(r'[0-9]', \"\", temp) #removes #s\n",
      "        temp = temp.lower()\n",
      "        temp = re.sub(r\"\\s+\", \" \", temp) #removing white space\n",
      "        temp = temp.split()\n",
      "        #print temp\n",
      "        #creating betas\n",
      "        x = np.zeros(M)\n",
      "        \n",
      "        for word in temp:\n",
      "            if word in V:\n",
      "                j = V.index(word)\n",
      "                x[j] = 1\n",
      "        mu = sum(g_beta * x) + g_b0\n",
      "        \n",
      "        '''\n",
      "        \n",
      "        ind = [] #list of indices eg. [34,78,90]\n",
      "        for word in temp:\n",
      "            if word in V:\n",
      "                j = V.index(word)\n",
      "                ind.append(j)\n",
      "                x[j] = 1\n",
      "        betas=[]\n",
      "        if not ind: #checking for empty list\n",
      "            continue\n",
      "        else:\n",
      "            for i in range(len(ind)):\n",
      "                betas.append(g_beta[ind[i]])\n",
      "        #print 'betas are', betas\n",
      "        #prediction and writing out files\n",
      "        mu = sum(betas) + g_b0\n",
      "        '''\n",
      "        pi  = exp(mu)/ (1 + exp(mu))\n",
      "        y_predict = 0\n",
      "        if pi > 0.5:\n",
      "            y_predict = 1\n",
      "        #y_predict = get_y(pi)\n",
      "        \n",
      "        \n",
      "        if l[k]['label'] != '?':\n",
      "            ## the tweet is labeled, then\n",
      "            y_label = l[k]['label']\n",
      "            if y_predict != y_label:\n",
      "                errors = errors + 1\n",
      "            else:\n",
      "                pass # correct\n",
      "            # no matter what we predict, we update the parameters\n",
      "            # update step\n",
      "            g_t = g_t + 1\n",
      "            eta = learning(learning_type, g_t)\n",
      "            # the function to online update the parameters\n",
      "            updated_beta = online_update_beta_l2(y_label, mu, x, g_beta, g_b0, eta, rambda)\n",
      "            \n",
      "            #print 'true label is ', l[k]['label'] \n",
      "            #print temp\n",
      "            #print updated_beta[1][ind] - beta[ind]\n",
      "    \n",
      "            g_b0 = updated_beta[0]\n",
      "            g_beta = updated_beta[1]\n",
      "            \n",
      "        else: ## for unlabeled data\n",
      "            id_and_label = \"<\"+str(l[k]['id'])+\"> <\"+str(y_predict)+\"> \"\n",
      "            f.write(\"%s\" % id_and_label)\n",
      "        \n",
      "        #print 'true label is', l[k]['label']\n",
      "        #print id_and_label\n",
      "        #print 'error count is', error_count\n",
      "    return [g_beta, g_b0, g_t, errors]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# input the data:\n",
      "lwishes=DAL.create('wishes-labelled')\n",
      "##testing the other data\n",
      "test = lwishes.subsets()[20:22] \n",
      "print 'The number of days to predict on is', len(test)\n",
      "i = 0\n",
      "g_beta = np.zeros(M)\n",
      "g_b0 = 0\n",
      "g_error_vec = []\n",
      "g_t = 0 #counting the number of iterations\n",
      "g_ones = 0# count of labelled one data\n",
      "f = open('predict_unlabelled.txt','w')\n",
      "\n",
      "learn_type = 1 # 1,2,3,4,5,6,7,8,9, different learning rate respectively\n",
      "print 'Here day 0 -- Dec 20, 2012, day 1 --Dec 21, 2012, ....'\n",
      "\n",
      "error_rate_temp = []\n",
      "total_errors = 0.0\n",
      "total_tweet = 0\n",
      "l = []\n",
      "t1 = time.clock()\n",
      "for day in test: # 44 days in total\n",
      "    i = i + 1\n",
      "    for tweet in lwishes.iter(day):\n",
      "        l.append(tweet)\n",
      "        total_tweet += 1\n",
      "        if total_tweet%1000 == 0:\n",
      "            #print '--'\n",
      "            #print total_tweet\n",
      "            L = len(l)\n",
      "            result = online_ridge_logistic(learn_type, g_beta, g_b0, g_t, f)\n",
      "            g_beta = result[0]\n",
      "            g_b0 = result[1]\n",
      "            g_t = result[2]\n",
      "            total_errors = total_errors + result[3]\n",
      "            error_rate_temp.append(total_errors / g_t)\n",
      "            #print total_errors / g_t\n",
      "            l = []\n",
      "    print 'after day ' + str(i) + \" \" + str(total_tweet) + \" got trained\" \n",
      "# for the last part less then 1000\n",
      "L = len(l)\n",
      "result = online_ridge_logistic(learn_type, g_beta, g_b0, g_t, f)\n",
      "g_beta = result[0]\n",
      "g_b0 = result[1]\n",
      "g_t = result[2]\n",
      "total_errors = total_errors + result[3]\n",
      "t2 = time.clock()\n",
      "print t2 - t1\n",
      "f.close()\n",
      "print 'The average error rate for labeled data is', total_errors / g_t\n",
      "plot(range(int(total_tweet / 1000)), error_rate_temp)\n",
      "show()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The number of days to predict on is 2\n",
        "Here day 0 -- Dec 20, 2012, day 1 --Dec 21, 2012, ....\n",
        "after day 1 28008 got trained"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "after day 2 58299 got trained"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "26.72"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "The average error rate for labeled data is 0.0298044784649\n"
       ]
      },
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD9CAYAAACx+XApAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl01OWh//H3QKKUoISqGTSDBk0gCWASDKYtaqMRQoNE\nFIp4KuZq0Ny0XARcgJ9LoVaWKlUU2gu9iERbBFuRHBtSoBAXaBKV4AIoCRKcpJCWJchqYPj+/njK\nQCAMWSZMZubzOmdOmOQ733ke2zOfeXabZVkWIiIStNr5ugAiIuJbCgIRkSCnIBARCXIKAhGRIKcg\nEBEJcgoCEZEgd94gKCwsJDY2lpiYGGbOnNngNWPHjiUmJoaEhATKysrcv4+KiuL6668nKSmJG2+8\n0f37vXv3MmDAAHr06MHAgQOpra31QlVERKQ5PAaBy+VizJgxFBYWsnnzZhYvXsyWLVvqXVNQUEBF\nRQXl5eXMnz+f3Nxc999sNhtFRUWUlZVRWlrq/v2MGTMYMGAAW7duJS0tjRkzZni5WiIi0lgeg6C0\ntJTo6GiioqIIDQ1l5MiRLF++vN41+fn5ZGVlAZCSkkJtbS01NTXuvze0Xu3012RlZfHOO++0uCIi\nItI8IZ7+WF1dTbdu3dzPHQ4HJSUl572muroau92OzWbj9ttvp3379uTk5PDQQw8BUFNTg91uB8Bu\nt9cLjpNsNlvzayUiEqSas1mExxZBYz+Mz/XGH374IWVlZaxYsYK5c+fywQcfNPge53ofy7IC8vHL\nX/7S52VQ/VQ/1S/wHs3lMQgiIyNxOp3u506nE4fD4fGaqqoqIiMjAbjqqqsAuOKKK7jrrrv46KOP\nANMK2LVrFwA7d+4kIiKi2RUQEZGW8RgEycnJlJeXU1lZSV1dHUuWLCEzM7PeNZmZmeTl5QFQXFxM\neHg4drudw4cPc+DAAQAOHTrEypUr6d27t/s1ixYtAmDRokUMHTrU6xUTEZHG8ThGEBISwpw5c0hP\nT8flcpGdnU1cXBzz5s0DICcnh4yMDAoKCoiOjiYsLIyFCxcCsGvXLu6++24Ajh8/zs9+9jMGDhwI\nwKRJkxgxYgQLFiwgKiqKpUuXtmYd25zU1FRfF6FVqX7+TfULPjarJR1Lrchms7Woz0tEJNg093NT\nK4tFRIKcgkBEJMgpCEREgpyCQEQkyCkIRESCnIKgifbtg//6L/jmG1+XRETEOzR9tAn+9S/4z1II\nuneHZct8Wx4RkdNp+mgrq6qCW26BoUOhpAQ2bYJ33/V1qUREWk5B0AjbtsHNN8Po0TBlClx8Mcyd\nC2PHwuHDvi6diEjLKAiAAwcgNhbuvtt8wH/5JZxsXW3eDKmpMGkSPPbYqdcMGAD9+sH06T4psoiI\n1ygIgLVr4bLLYNgw+PhjMw7gcMCoUZCWZj7sc3LOft1vfwu//z1s3Xrhyywi4i0aLAZ+8Qu45hp4\n4gnz3LKgogL+/neIjobbbz/3a198EQoKYOVK0Fk6IuJLzf3cVBAAMTHw5z9DQkLTX3v8ONxwAzz5\nJIwY4f2yiYg0loKgmb7+Gn70I9i5s/nf6Netg3vuMeMJl17q3fKJiDSWpo8208qVZkygJd06/ftD\nejo884z3yiUicqEEfRD87W/mQ7ylfvMbeOstM/AsIuJPgrpr6NgxuOIKM+vHG8cmFxaa2UWffgrh\n4S2/n4hIU6hrqBlKSuDaa70TAgCDBsGQIWYWkoiIvwjqIPBWt9DpfvMb2LAB3nzTu/cVEWktCgIv\nB0HHjvDGG2b7CafTu/cWEWkNQTtGsGeP6Rb697/hoou8f//nnoM1a2DVKmh3WtxWVcHChbBlC7z+\nOrRv7/33FpHgpDGCJlq92uwm2hohADBxIhw9CrNnQ10dvP02ZGTA9dfDP/9pNrJbuLB13ltEpCmC\ntkXw4IPQty+MGdNqb8G2bfCDH5hv/T17mt1Lhw0z3UcffQR33mlmLHXq1HplEJHgoZXFTWBZ0K2b\n6brp0aNV3sLto4+gc+eG3+dnP4PrroNf/ap1yyAiwUFB0ASbNsEdd5jtJXy5UdyOHaZV8umnZrdT\nEZGW0BhBE6xcaWYL+Xq30GuugYcfhqee8m05RCS4BWUQ/O1vp84e9rXJk82K5LIyX5dERIJV0HUN\nHTkCdruZ49+5s9dv3yy//73Zp+jvf/d9K0VE/FerdQ0VFhYSGxtLTEwMM2fObPCasWPHEhMTQ0JC\nAmVnfLV1uVwkJSUxZMgQ9++mTJmCw+EgKSmJpKQkCgsLm1zw5vrwQzOFs62EAMBDD8GuXfDuu74u\niYgEI49B4HK5GDNmDIWFhWzevJnFixezZcuWetcUFBRQUVFBeXk58+fPJzc3t97fZ8+eTXx8PLbT\nvurabDYmTJhAWVkZZWVlDBo0yItV8uzkttNtSUgIPP88PP642QhPRORC8hgEpaWlREdHExUVRWho\nKCNHjmT58uX1rsnPzycrKwuAlJQUamtrqampAaCqqoqCggJGjx59VnPFVz1SGzZASopP3tqjjAwz\npXX+fF+XRESCTYinP1ZXV9OtWzf3c4fDQUlJyXmvqa6uxm63M378eJ5//nm+/fbbs+79yiuvkJeX\nR3JyMrNmzSK8gX2bp0yZ4v53amoqqampja3XOX3xBfTp0+LbeJ3NZjasy8iA+++HSy7xdYlEpK0r\nKiqiqKioxffxGAS2Ro5cNvRt/9133yUiIoKkpKSzCpqbm8sz/znO6+mnn+bRRx9lwYIFZ9339CDw\nhn/9y3S9XHmlV2/rNUlJkJYGs2aBl6suIgHozC/IU6dObdZ9PHYNRUZG4jxtC02n04njjJVPZ15T\nVVVFZGQk69evJz8/n+7du3PvvfeyZs0a7r//fgAiIiKw2WzYbDZGjx5NaWlpswrfVF98Ab17t+2Z\nOc8+C6+8Av/pXRMRaXUegyA5OZny8nIqKyupq6tjyZIlZGZm1rsmMzOTvLw8AIqLiwkPD6dr165M\nmzYNp9PJ9u3befPNN7ntttvc1+3cudP9+mXLltHnAvXVnAyCtqx7d9M1pG0nRORC8dg1FBISwpw5\nc0hPT8flcpGdnU1cXBzz5s0DICcnh4yMDAoKCoiOjiYsLIyF59hS8/RupokTJ7Jx40ZsNhvdu3d3\n36+1ff652dKhrXvySYiNhXHjICbG16URkUAXVAvKfvhDMyB7881evW2rmDYNNm6EpUt9XRIR8Rfa\ndO48LMssItuxA7p08dptW82hQ2bH0mXL4MYbfV0aEfEH2nTuPHbsgEsv9Y8QAAgLMzOHJk40ISYi\n0lqCJgj8YaD4TA88YLaeWLHC1yURkUCmIGjDQkJg+vRTx16KiLSGoAmCzz9vmyuKz+fOO6FXL3PE\npcJARFpD0ASBP7YIwCx+e/11M2Zw990KAxHxvqCYNXTsmBko3rPHHBzvj44dM2ccHzwIb78NHTr4\nukQi0tZo1pAH5eVmZ09/DQGA0FD405+gUye46y61DETEe4IiCPy1W+hMISEmDC69VGEgIt6jIPAz\nISHwxz+axXH9+5vzl9tm556I+IugCAJ/nTF0LidbBhMnmv2IbrkFvLAluYgEqaAIgkBqEZzUrh2M\nGGHq9vDDkJ1tzjJYv97XJRMRfxPws4YOH4bLL4f9+82Aa6A6dgwWLYKnn4a8PBgwwNclEpELrbmf\nmx63oQ4EW7aYzdsCOQTA1G/0aDMzaupUuP32tn0Aj4i0HQHfNfT554HXLeTJPfeYIznfe8/XJRER\nfxHwQRCI4wOetG8PkyfDr3/t65KIiL8IiiAIpBlDjXHffVBRAf/4h69LIiL+IOCDINi6hsCMF0ya\npFaBiDROQM8a2rsXoqLMjKFgGzg9ehSioyE/3z/OaRaRltNeQw3YtMm0BoItBMBsSvf442oViMj5\nBXQQBGO30OkeesgsMPviC1+XRETasoAOgmCbMXSmjh1h/Hh47jlfl0RE2rKAD4JgmzF0pp//HFav\nhq++8nVJRKStCtggsCx1DQFccgn8z//AtGm+LomItFUBGwT//CdcdBFccYWvS+J7jzwCK1fCJ5/4\nuiQi0hYFbBA4nWbqqJizC379a9MyaJuThUXElwI2CGproUsXX5ei7XjgAbND6R//6OuSiEhbE9BB\nEB7u61K0He3awcsvm8NsDhzwdWlEpC05bxAUFhYSGxtLTEwMM2fObPCasWPHEhMTQ0JCAmVlZfX+\n5nK5SEpKYsiQIe7f7d27lwEDBtCjRw8GDhxIbW1tC6txNgXB2X74Q3N4jQaOReR0HoPA5XIxZswY\nCgsL2bx5M4sXL2bLli31rikoKKCiooLy8nLmz59Pbm5uvb/Pnj2b+Ph4bKct750xYwYDBgxg69at\npKWlMWPGDC9WyVAQNGzGDPjDH6C83NclEZG2wmMQlJaWEh0dTVRUFKGhoYwcOZLly5fXuyY/P5+s\nrCwAUlJSqK2tpaamBoCqqioKCgoYPXp0vf0vTn9NVlYW77zzjlcrBQqCc7nqKnjiCZgwwdclEZG2\nwuMJZdXV1XTr1s393OFwUFJSct5rqqursdvtjB8/nueff55vv/223mtqamqw2+0A2O12d3CcacqU\nKe5/p6amkpqa2qhKAezbp1lD5/LII6ZVsGIF/OQnvi6NiDRXUVERRUVFLb6PxyCwNXK3tjN3u7Ms\ni3fffZeIiAiSkpI8FtRms53zfU4PgqZSi+DcLr4YXnoJxo0zYwYXXeTrEolIc5z5BXnq1KnNuo/H\nrqHIyEicTqf7udPpxOFweLymqqqKyMhI1q9fT35+Pt27d+fee+9lzZo13H///YBpBezatQuAnTt3\nEhER0azCe6Ig8GzwYLNN9Qsv+LokIuJrHoMgOTmZ8vJyKisrqaurY8mSJWRmZta7JjMzk7y8PACK\ni4sJDw+na9euTJs2DafTyfbt23nzzTe57bbb3NdlZmayaNEiABYtWsTQoUO9XjEFwfnNnQu//S18\n+aWvSyIivuSxaygkJIQ5c+aQnp6Oy+UiOzubuLg45s2bB0BOTg4ZGRkUFBQQHR1NWFgYCxcubPBe\np3f/TJo0iREjRrBgwQKioqJYunSpF6tkKAjOLyoKpkyB7Gx4/31z3rGIBJ+APaHMbodPP4WuXb1Y\nqAB04gT8+McwYoTZgkJE/FdzPzcDMggsy5zQtX+/+SmeffUV3HQTfPSRZlqJ+DMdVXmao0fNlgoK\ngcbp2RMee8ycaNY2vxaISGsKyCDQ+EDTPfoo7N0Lr73m65KIyIWmIBAAQkLg1VfNpnQ7d/q6NCJy\nISkIxC0hAXJyTBfR4cO+Lo2IXCgKAqnnqafM8Zbx8bBsmcYMRIJBQAbBvn0Kgua6+GJYvNh0Ez31\nFAwaBFu3+rpUItKaAjII1CJoudtug40bTRD07w+TJ8PBg74ulYi0BgWBnFNoKIwfD599Zs6A7tsX\nNmzwdalExNsUBHJeV14Jb7wBzz5rWggvv6yxA5FAoiCQRrvnHiguhtdfhzvvhD17fF0iEfEGBYE0\nybXXwrp10KMHJCXBBx/4ukQi0lIKAmmyiy4y5xj87//C8OFQWOjrEolISwRsEHTp4utSBL6MDPjz\nnyErCyoqfF0aEWmugA0CtQgujJtvhqlTzZjBgQO+Lo2INIeCQFrsv//bbGM9apQ530BE/EvABYFl\nmSDo3NnXJQkur7wCu3fDr37l65KISFMFXBAcOWJ20rz4Yl+XJLhcdJEZL3j1VXj7bV+XRkSaIuCC\nQPsM+U7XriYEcnLgiy98XRoRaayACwKND/hWcjK89BIMHAjr1/u6NCLSGAoC8bqf/Qz+8AcYOhQW\nLfJ1aUTkfBQE0ioGD4aiIrM/0WOPgcvl6xKJyLkoCKTVxMdDSQmUlcEdd8D+/b4ukYg0REEgreqy\ny8wWFNddBykp8OWXvi6RiJxJQSCtLjQU5swxXUQ336xxA5G2JiCDQPsMtU2jR8OaNTBjhtmfSCee\nibQNARkEahG0XX36wMcfQ7t2ZqrpZ5/5ukQioiCQCy4sDBYuhCefhLQ0M9VURHznvEFQWFhIbGws\nMTExzJw5s8Frxo4dS0xMDAkJCZSVlQFw9OhRUlJSSExMJD4+nsmTJ7uvnzJlCg6Hg6SkJJKSkij0\n4ob2CgL/MWoUfPihOdvgqad0/KWIr4R4+qPL5WLMmDGsXr2ayMhI+vXrR2ZmJnFxce5rCgoKqKio\noLy8nJKSEnJzcykuLqZDhw6sXbuWjh07cvz4cW666SbWrVtH//79sdlsTJgwgQkTJni9Qtpiwr/0\n7GnCYPBgqKmB3//e7BUlIheOxxZBaWkp0dHRREVFERoaysiRI1m+fHm9a/Lz88nKygIgJSWF2tpa\nampqAOjYsSMAdXV1uFwuupw2imu10tc/tQj8zxVXmEHkHTvgpz81GweKyIXj8btXdXU13bp1cz93\nOByUlJSc95qqqirsdjsul4sbbriBbdu2kZubS3x8vPu6V155hby8PJKTk5k1axbhDXx6T5kyxf3v\n1NRUUlNTz1shBYF/6tQJ3n3XzCYaNAiWL9f/jiLnU1RURFFRUYvv4zEIbDZbo25y5rf7k69r3749\nGzduZP/+/aSnp1NUVERqaiq5ubk888wzADz99NM8+uijLFiw4Kz7nh4EjSuHziLwZxddBH/8I4wb\nBz/+MaxYAVdd5etSibRdZ35Bnjp1arPu47FrKDIyEqfT6X7udDpxOBwer6mqqiIyMrLeNZ07d2bw\n4MF8/PHHAERERGCz2bDZbIwePZrS0tJmFf5Mhw6ZcwguusgrtxMfaNcOZs+GkSPhBz+ADRt8XSKR\nwOcxCJKTkykvL6eyspK6ujqWLFlCZmZmvWsyMzPJy8sDoLi4mPDwcOx2O7t376a2thaAI0eOsGrV\nKpKSkgDYuXOn+/XLli2jT58+XqmMuoUCg80GkyfDiy9Cejr85S++LpFIYPPYNRQSEsKcOXNIT0/H\n5XKRnZ1NXFwc8+bNAyAnJ4eMjAwKCgqIjo4mLCyMhQsXAubDPisrixMnTnDixAlGjRpFWloaABMn\nTmTjxo3YbDa6d+/uvl9LKQgCy7Bh0L272c5682YzxbSRvZUi0gQ2q7Wm77SQzWZr8syiDz+EiRNh\n3bpWKpT4xM6dcOedZuO6V1+F733P1yU628GD5kCe2lrTvWWznXp89505z/nf/z712LvXfGm55hq4\n+upTj6uuMgvuwsKgY8dTP0NDT93v5P07dGib/y3Ed5rzuQnnaRH4G+0zFJiuvBLeew8efBBuucVs\nWnfaBDSf+/RTuOce6NsXEhPNpIXTH5ddBgkJZprs5Zebn9//vlnz8s035rFjh7lPYaEZ6zp82DwO\nHTKP48dP3e/ECfPT5YKnn4ZHH4X27X39X0H8WcAFgbqGAtP3vgd/+hP87ndmRtHDD5uuIl9+I7Ys\nmDfPfBi/+CLcd1/TXt+5M0RFNf/9t2+H7GxYtgxee80szhNpjoDaa0hBENhsNvjFL8w354oK6N3b\nfIP2hdpaGDHCBMG6dU0PAW/o3h1WrzZHg/bvb8JIJ8FJcygIxO9cdRUsWQJz58LPf266ZU6biNbq\n3n/fdAPZ7fCPf0CPHhfuvc/Urh2MGQPFxfD226a1VF7uu/KIfwqoINA+Q8Fl0CD44gu49lpz+tnm\nza37fp98Aj/5Cdx/P8yaZQ7b6dChdd+zsaKjzTjK8OHwwx/CtGlQV+frUom/CKggUIsg+HTsCNOn\nw3PPwW23mW/G3rZ5s/mAHTLEnL381Vdw113ef5+WatfOrMr++GMzg+6GG0yLReR8FAQSEEaNggUL\nzIf13/7mnXvu2WP2PkpNNS2OigozRnHxxd65f2uJioK//tUMpg8bZsq8f7+vSyVtmYJAAsbgwfDO\nO6brZvHilt2rrMycoNali+lzf/xx0/rwFzabGTvZtAmOHYNevWDpUp35IA1TEEhA6d/fzKR5/HF4\n5ZXmffC98QYMHGjOVn7pJf/exLBLF5g/3wTjs8+acRUNJsuZFAQScPr0MX3k8+aZufVPPmmmnJ4v\nFI4dg0cegalTYe1a8406UNx8s9nAb+BAM5j8y1/q3Ac5JaC2mLjsMjOQd/nlrVQo8SuWZQZOly6F\nt94yu9L+9KfmnOSwMNPXf/JRV2cWqV16qWkRBPIXiqoqGD/eBMNvfwuZmdrDKVA0d4uJgAkCyzL7\nsRw5Yn6KnO5kKLz1lplJc/So+fD/7jvzOHYMHnrIrBJuF1Dt5HMrLDR7c9ls8P/+nxlY1lYV/i3o\ng+DAAbPQ6MCBViyUSICxLDPD6LnnzEZ4kyaZlco608M/BX0QOJ3wox+ZnyLSNJYFRUVmIdpXX5lz\nIOLiTj2uvjp4Wkr+rLlBEDD/02qgWKT5bDa49VZYtcqcF923L1RWmjGEm26CSy4xP996S/sZBaKA\n2X1UQSDiHUlJ5nG6b781M6lmzjTjCU88YdZrtPXFddI4AdMi0D5DIq3n0kvN4UDr1pkV3MuWmT2e\nXnjBfAkT/xYwQaAWgUjrs9nM4UAFBeaxYYM5ZW34cLOq+7vvfF1CaQ4FgYg0S0KCOSyostIMLr/0\nkpm59/DDZifU48d9XUJpLAWBiLRIly5mDUZRkdmj6brrzC6oERFmdfZrr13Y8yKk6QJm+uiECRAZ\nac5vFRHf++c/zU6wK1aY/Z+uucZ0K8XGmq0/evY0LQitavaeoF9H8OCDZsOx7OxWLJSINMvx4+as\niOJis07h5OPQIRMIqalm99ibbtJitpZobhBo+qiItLqQEPMhf9NN9X9fW2sO/lm9GiZPNuGQlmZC\nISMDunb1TXmDTcC0CG67zewymZbWioUSkVb1r3+ZPZD++ldYudIMSN9zj9kHKSKi/rUHDpi1DYWF\nZmyid2+48UZziFCvXsG5b1LQdw317Qv/93/mp4j4v6NHzRjDkiVmqmpystk9dv9+8+H/0UfmQ3/Q\nIHMs56ZNUFICpaVmfKJvXxMiDz9sWiTBIOiD4NprTfPy2mtbsVAi4hOHD5sw+MtfzCyln/zEbInR\nqVPD1+/da0LhhRdg1y548UVzFkOgC/og+P73zZmy3/9+KxZKRPyKZUF+Pjz2mBmUfuEFM2spUAV1\nEJw4YWYaHD0aPE1AEWm8776DOXPM8aPDh0NUlJnJdOzYqUfnztCvn3l06eLrEjdPqwVBYWEh48aN\nw+VyMXr0aCZOnHjWNWPHjmXFihV07NiR1157jaSkJI4ePcqPf/xjvvvuO+rq6rjzzjuZPn06AHv3\n7uWee+5hx44dREVFsXTpUsLPmPLTlArt3w/dupmNsUREzuXf/4bf/c5MWw0JMYdYnXzs2WPGHT75\nxMxWSknxHAon1z+c/rNDB9Nd1amT2bG1UyfTS3Ghzr1ulSBwuVz07NmT1atXExkZSb9+/Vi8eDFx\ncXHuawoKCpgzZw4FBQWUlJTwyCOPUFxcDMDhw4fp2LEjx48f56abbmLWrFn079+fJ554gssvv5wn\nnniCmTNnsm/fPmbMmNHsCu3YYc5k/eabJtdfRKQelwu2bDGDzh9/3PBhVyc/mk7/aVmm5XHgABw8\neOrnnj3mnOgHH4ShQ01YtJZWWUdQWlpKdHQ0UVFRAIwcOZLly5fXC4L8/HyysrIASElJoba2lpqa\nGux2Ox07dgSgrq4Ol8tFl/9Ea35+Pu+99x4AWVlZpKamnhUETaE1BCLiLe3bm6movXubD++WOnLE\nbMi3YAH84hdw773mvklJbWdVtccgqK6uplu3bu7nDoeDkpKS815TVVWF3W7H5XJxww03sG3bNnJz\nc4mPjwdwBwWA3W6npqamwfefMmWK+9+pqamkpqY2eJ2CQETaqu99z3z433uv2aBv0SK4+24ICzPr\nI+6+26yXaE4oFBUVUVRU1OIyegwCWyNLdmZT5OTr2rdvz8aNG9m/fz/p6ekUFRWd9WFus9nO+T6n\nB4EnCgIR8QdRUfDLX8LTT5vprW+/bYLAZjM/777bjE009ljQM78gT506tVnl8vh2kZGROE87BNjp\ndOJwODxeU1VVRWRkZL1rOnfuzODBg/nkk08A0wrYtWsXADt37iTizCWDTaQgEBF/0q6dGTd4/nnY\nts2sj+jQAUaPhqoqH5TH0x+Tk5MpLy+nsrKSuro6lixZQmZmZr1rMjMzycvLA6C4uJjw8HDsdju7\nd++m9j9HFx05coRVq1aRmJjofs2iRYsAWLRoEUOHDm1RJRQEIuKvbDZITIRnnzWro6+++sKXwWPX\nUEhICHPmzCE9PR2Xy0V2djZxcXHMmzcPgJycHDIyMigoKCA6OpqwsDAWLlwImG/6WVlZnDhxghMn\nTjBq1CjS/rMR0KRJkxgxYgQLFixwTx9tCQWBiEjzBcSCsvHjzTqCCRNauVAiIm1Yc6ePBsQJZbW1\n/rsSUETE1wImCNQ1JCLSPAERBPv2Xbgl3CIigSYggmDHDt+MtIuIBAK/Hyz+7jvTGjh4UDuPikhw\nC9rB4q+/NjOGFAIiIs3j90FQUQExMb4uhYiI//L7ICgvVxCIiLREQARBdLSvSyEi4r8CIgjUIhAR\naT6/DwKNEYiItIxfTx89etSsKNbUURGRIJ0++vXXZiGZQkBEpPn8OgjULSQi0nJ+HQQaKBYRaTm/\nDwJNHRURaRm/DgJ1DYmItJxfB4G6hkREWs5vp49q6qiISH1BN3102za45hqFgIhIS/ltEGh8QETE\nO/w2CDQ+ICLiHQoCEZEg57dBUFGhNQQiIt7gt0GgFoGIiHf45fTRI0egSxc4dAjat7/ABRMRaaOC\navrotm0QFaUQEBHxBr8MAk0dFRHxHr8MAo0PiIh4z3mDoLCwkNjYWGJiYpg5c2aD14wdO5aYmBgS\nEhIoKysDwOl0cuutt9KrVy969+7Nyy+/7L5+ypQpOBwOkpKSSEpKorCwsEmFVhCIiHiPxyBwuVyM\nGTOGwsJCNm/ezOLFi9myZUu9awoKCqioqKC8vJz58+eTm5sLQGhoKC+++CKbNm2iuLiYuXPn8uWX\nXwJmQGPChAmUlZVRVlbGoEGDGnz/0tKGy6WpoyIi3uMxCEpLS4mOjiYqKorQ0FBGjhzJ8uXL612T\nn59PVla9s/dnAAAJlklEQVQWACkpKdTW1lJTU0PXrl1JTEwEoFOnTsTFxVFdXe1+XWNGtp99tuHf\nq0UgIuI9Hrdsq66uplu3bu7nDoeDkpKS815TVVWF3W53/66yspKysjJSUlLcv3vllVfIy8sjOTmZ\nWbNmER4eftb7v/feFHJy4MorITU1ldTUVA4fht274bS3FBEJSkVFRRQVFbX4Ph6DwGazNeomZ367\nP/11Bw8eZPjw4cyePZtOnToBkJubyzPPPAPA008/zaOPPsqCBQvOuu+vfjWF99+HefNO/e7rrzV1\nVEQETn1BPmnq1KnNuo/HrqHIyEicTqf7udPpxOFweLymqqqKyMhIAI4dO8awYcO47777GDp0qPua\niIgIbDYbNpuN0aNHU3qOwYCHH4Z//AM+//zU79QtJCLiXR6DIDk5mfLyciorK6mrq2PJkiVkZmbW\nuyYzM5O8vDwAiouLCQ8Px263Y1kW2dnZxMfHM27cuHqv2blzp/vfy5Yto0+fPg2+f8eOMGEC/PrX\np36nIBAR8S6PXUMhISHMmTOH9PR0XC4X2dnZxMXFMe8/fTU5OTlkZGRQUFBAdHQ0YWFhLFy4EIB1\n69bxxhtvcP3115OUlATA9OnTGTRoEBMnTmTjxo3YbDa6d+/uvl9DcnPhuutgyxaIizNBcMMN3qq+\niIj4xV5D06bB5s3wxhtw663w5JNw++0+LqCISBvT3L2G/OKgxzFjTKugvFxdQyIi3uYXLQKAqVNN\nqyA/3+w62s4vN8cQEWk9zW0R+E0Q7Ntnpo06HLBpk+/KJSLSVgX8NtRdusDYsRAb6+uSiIgEFr9p\nEQC4XHDgADSwCFlEJOgFfNeQiIh4FvBdQyIi0joUBCIiQU5BICIS5BQEIiJBTkEgIhLkFAQiIkFO\nQSAiEuQUBCIiQU5BICIS5BQEIiJBTkEgIhLkFAQiIkFOQSAiEuQUBCIiQU5BICIS5BQEIiJBTkEg\nIhLkFAQiIkFOQSAiEuQUBCIiQU5BICIS5BQEPlBUVOTrIrQq1c+/qX7B57xBUFhYSGxsLDExMcyc\nObPBa8aOHUtMTAwJCQmUlZUB4HQ6ufXWW+nVqxe9e/fm5Zdfdl+/d+9eBgwYQI8ePRg4cCC1tbVe\nqo5/CPT/I6p+/k31Cz4eg8DlcjFmzBgKCwvZvHkzixcvZsuWLfWuKSgooKKigvLycubPn09ubi4A\noaGhvPjii2zatIni4mLmzp3Ll19+CcCMGTMYMGAAW7duJS0tjRkzZrRS9URE5Hw8BkFpaSnR0dFE\nRUURGhrKyJEjWb58eb1r8vPzycrKAiAlJYXa2lpqamro2rUriYmJAHTq1Im4uDiqq6vPek1WVhbv\nvPOO1ysmIiKNZHnw1ltvWaNHj3Y/f/31160xY8bUu+aOO+6w1q1b536elpZmffzxx/Wu2b59u3X1\n1VdbBw4csCzLssLDw91/O3HiRL3nJwF66KGHHno08dEcIXhgs9k8/dnNfG43/LqDBw8yfPhwZs+e\nTadOnRp8j4be58x7iohI6/DYNRQZGYnT6XQ/dzqdOBwOj9dUVVURGRkJwLFjxxg2bBj33XcfQ4cO\ndV9jt9vZtWsXADt37iQiIqLlNRERkWbxGATJycmUl5dTWVlJXV0dS5YsITMzs941mZmZ5OXlAVBc\nXEx4eDh2ux3LssjOziY+Pp5x48ad9ZpFixYBsGjRonohISIiF5bNOk8fzIoVKxg3bhwul4vs7Gwm\nT57MvHnzAMjJyQFwzywKCwtj4cKF9O3blw8//JBbbrmF66+/3t31M336dAYNGsTevXsZMWIE33zz\nDVFRUSxdupTw8PBWrqqIiDSoWSMLrWzFihVWz549rejoaGvGjBm+Lk6LPPDAA1ZERITVu3dv9+/2\n7Nlj3X777VZMTIw1YMAAa9++fT4sYct88803VmpqqhUfH2/16tXLmj17tmVZgVPHI0eOWDfeeKOV\nkJBgxcXFWZMmTbIsK3DqZ1mWdfz4cSsxMdG64447LMsKrLpdc801Vp8+fazExESrX79+lmUFVv32\n7dtnDRs2zIqNjbXi4uKs4uLiZtWvza0sbszaBX/ywAMPUFhYWO93gbSOoqH1Ilu2bAmYOnbo0IG1\na9eyceNGPvvsM9auXcuHH34YMPUDmD17NvHx8e6WeyDVzWazUVRURFlZGaWlpUBg1e+RRx4hIyOD\nLVu28NlnnxEbG9u8+l2A0GqS9evXW+np6e7n06dPt6ZPn+7DErXc9u3b67UIevbsae3atcuyLMva\nuXOn1bNnT18VzevuvPNOa9WqVQFZx0OHDlnJycnWF198ETD1czqdVlpamrVmzRp3iyBQ6mZZlhUV\nFWXt3r273u8CpX61tbVW9+7dz/p9c+rX5loE1dXVdOvWzf3c4XC4F6IFipqaGux2O2BmUNXU1Pi4\nRN5RWVlJWVkZKSkpAVXHEydOkJiYiN1ud2+bEij1Gz9+PM8//zzt2p36KAiUuoFpEdx+++0kJyfz\nhz/8AQic+m3fvp0rrriCBx54gL59+/LQQw9x6NChZtWvzQVBY9cuBIpzraPwNwcPHmTYsGHMnj2b\nSy65pN7f/L2O7dq1Y+PGjVRVVfH++++zdu3aen/31/q9++67REREkJSUdM51O/5at5PWrVtHWVkZ\nK1asYO7cuXzwwQf1/u7P9Tt+/DgbNmzg5z//ORs2bCAsLOysbqDG1q/NBUFj1i74u0BbR3Fyvcio\nUaPcU4EDrY4AnTt3ZvDgwXzyyScBUb/169eTn59P9+7duffee1mzZg2jRo0KiLqddOWVVwJwxRVX\ncNddd1FaWhow9XM4HDgcDvr16wfA8OHD2bBhA127dm1y/dpcEDRm7YK/C6R1FNY51osESh13797t\n3h33yJEjrFq1iqSkpICo37Rp03A6nWzfvp0333yT2267jddffz0g6gZw+PBhDhw4AMChQ4dYuXIl\nffr0CZj6de3alW7durF161YAVq9eTa9evRgyZEjT6+fl8QuvKCgosHr06GFdd9111rRp03xdnBYZ\nOXKkdeWVV1qhoaGWw+GwXn31VWvPnj1WWlpaQExf++CDDyybzWYlJCRYiYmJVmJiorVixYqAqeNn\nn31mJSUlWQkJCVafPn2s3/zmN5ZlWQFTv5OKioqsIUOGWJYVOHX7+uuvrYSEBCshIcHq1auX+7Mk\nUOpnWZa1ceNGKzk52br++uutu+66y6qtrW1W/c67oExERAJbm+saEhGRC0tBICIS5BQEIiJBTkEg\nIhLkFAQiIkFOQSAiEuT+P8HAnGdiiMy3AAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x4697250>"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Short commentary:\n",
      "    \n",
      "    Based on our results, it seems like the best step size is 0.3/sqrt(t), which gives us an error rate of 0.030. This was only slightly better than most of the other rates which were around that level as well. The worst rates we got were from step sizes of 1, 0.3/t and 1/t which were near 0.08. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "    "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}